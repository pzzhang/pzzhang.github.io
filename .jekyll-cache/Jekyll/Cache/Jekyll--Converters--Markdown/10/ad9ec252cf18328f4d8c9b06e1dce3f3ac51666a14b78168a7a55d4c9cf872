I"$<p>Four papers are accepted to CVPR2022. <a href="https://arxiv.org/abs/2112.03857">“Grounded Language-Image Pre-training (GLIP)”</a>, <a href="https://arxiv.org/pdf/2112.09106.pdf">“RegionCLIP: Region-based Language-Image Pretraining”</a>, <a href="https://arxiv.org/pdf/2111.02387.pdf">“An Empirical Study of Training End-to-End Vision-and-Language Transformers”</a> and “Unified Contrastive Learning in Image-Text-Label Space”. Congratulations to all collaborators! Source code is opensourced or is under opensource process!</p>
:ET